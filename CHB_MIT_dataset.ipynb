{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHB_MIT dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunsinghrathore/Subject-Independent-Emotion-Recognition/blob/main/CHB_MIT_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKK5YC1jezok"
      },
      "source": [
        "#01. Overview of Datasets\n",
        "\n",
        "by [David Luke Elliott](https://www.lancaster.ac.uk/psychology/about-us/people/david-elliott)\n",
        "/ [GitHub](https://github.com/Eldave93) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGokDfSye_RD"
      },
      "source": [
        "Welcome to the first notebook in my series on demonstrating the application of signal processing and machine learning classification to epileptic seizure detection!\n",
        "\n",
        "The purpose for this notebook is:\n",
        "1. To get a basic understanding of what a seizure is. \n",
        "2. How EEG can be used to measure it.\n",
        "3. What datasets are out there to start building machine learning algorithms to detect it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzXAWsV89Zsd"
      },
      "source": [
        "## Background: Epilepsy and Electroencephalography\n",
        "\n",
        "Epilepsy is the tendency to have unprovoked and recurrent seizures. Epileptic seizures are often accompanied by an alteration of consciousness, symptomatic of abnormal, excessive, or synchronized neuronal discharges which are either widespread or localized in nature<sup>1,2</sup>. There are over 40 types of epilepsy<sup>3</sup> and over 40 different types of seizure; of which individuals may experience several<sup>4</sup>. Clinical manifestations of epilepsy are dependent on several factors; such as the particular epilepsy syndrome, patients age, the brain area that generates seizures, and if discharges remain local or propagate to other brain areas<sup>1</sup>. \n",
        "\n",
        "Whilst all seizures result from an increase in cellular excitability, the mechanisms of synchronization differ between seizures, broadly categorising them as focal or generalized epilepsies. Although historically atonic, tonic, clonic, tonic-clonic, myoclonic, or absence seizures were thought to be “primarily generalized” in nature, there is an increasing acceptance that these still originate in local microcircuits which then propagate to other areas<sup>5,6</sup>; representative of a larger shift towards viewing epilepsy as a dysfunction of neuronal networks than single sources<sup>7</sup>. \n",
        "\n",
        "The diagnosis of epilepsy relies on the identification of clinical features specific to a particular epilepsy syndrome. Electroencephalography (EEG), magnetic resonance imaging (MRI) reports, and verbal descriptions of seizures are the most commonly available information to neurologists; with hospital records, seizure diaries, and videos of patient events desirable but not always available<sup>8</sup>. In clinic scalp EEG is commonly used as it provides an un-invasive, easy, and inexpensive method to characterise the mean electrical activity generated by the synchronous firing of open field neurons at a high temporal resolution. \n",
        "\n",
        "The time series gained from an EEG amplifier is a digital sample of analogue voltage recordings generated by the synchronous firing of open field neurons in the brain. The digital EEG therefore approximates the continuous time signal of neural activity through the discrete sampling of points. The typical sampling rates for clinical EEG typically lie between 200 and 500Hz, meaning the spectral components generated by the cortex predominately focused on by neurologists, typically within the 1 to 30Hz range, can be estimated without aliasing<sup>12</sup>.\n",
        "\n",
        "Typically, in the UK national health service (NHS), patients have an approximately 30-minute scalp EEG assessment, during which the patient may be asked to hyperventilate or exposed to photic stimulation to provoke a seizure. If a diagnosis is suspected, but not gained, a patient may then have a longer EEG assessment. Human experts, trained to qualitatively assess EEG records for epilepsy, will look at the EEG record to identify the presence and type of epilepsy, assessing the data based on a number of aspects. The spatial and temporal information is used to report seizures when the EEG appears to have seizure-like oscillations over a long duration and a number of channels. The pattern of EEG needs to be clearly different from the background activity, with consideration given to the difference of awake and asleep background EEG. The appearance of an epileptic event comparitive to artefacts or rhythms is also required to avoid falsely classify artefactual activity<sup>9</sup>. \n",
        "\n",
        "Manual review of EEG is time consuming, expensive, and prone to error<sup>9</sup>. Indeed, it has been found below 80\\% of events were similarly identified between two or more experts on a previously marked EEG record<sup>10</sup>. Indeed, in developed countries, such as the UK, misdiagnosis rates are estimated to be between 20-30 percent, and consequently costly to the health service<sup>11</sup>. The limitations of scalp EEG no doubt factor into these misclassifications. Scalp EEG has limited spatial sensitivity, as the signal needs to propagate through several layers of non-neural tissue, and therefore require larger brain areas to have synchronous activity. Scalp EEG is also often contaminated with artefacts, which represent noise caused by sources other than the brain such as by ambient electromagnetic interference, eye blinks, and muscle movements. Due to these limitations, intra-cranial EEG is therefore more often used for pre-surgical analysis to determine brain regions for surgical resection, as it is less effected by artefacts and has better spatial sensitivity<sup>9</sup>.\n",
        "\n",
        "---\n",
        "\n",
        "1. Giourou,  E.,  Stavropoulou-Deli,  A.,  Giannakopoulou,  A.,Kostopoulos, G. K., & Koutroumanidis, M. (2015). In-troduction to Epilepsy and Related Brain Disorders. InN. S. Voros & C. P. Antonopoulos (Eds.),Cyberphys-ical systems for epilepsy and related brain disorders:Multi-parametric monitoring and analysis for diagno-sis and optimal disease management(Chap. 2, pp. 11–38). doi:10.1007/978-3-319-20049-1\n",
        "\n",
        "2. Krumholz, A., Wiebe, S., Gronseth, G., Shinnar, S., Levisohn, P., Ting, T., . . . French, J. (2007). Evaluating an Apparent Unprovoked First Seizure in Adults (An Evidence-Based Review). Neurology, 69(21), 1996– 2007. doi:10.1212/01.wnl.0000285084.93652.43\n",
        "\n",
        "3. Berg,  A.  T.,  Berkovic,  S.  F.,  Brodie,  M.  J.,  Buchhalter,  J.,Cross, J. H., Van Emde Boas, W., . . .  Scheffer, I. E.(2010). Revised terminology and concepts for organi-zation of seizures and epilepsies: Report of the ILAECommission on Classification and Terminology, 2005-2009.Epilepsia,51(4), 676–685. doi:10.1111/j.1528-1167.2010.02522.x\n",
        "\n",
        "4. Blume, W. T., Lüders, H. O., Mizrahi, E., Tassinari, C., VanEmde Boas, W., & Engel J., J. (2001). Glossary of de-scriptive  terminology  for  ictal  semiology:  Report  ofthe  ILAE  Task  Force  on  classification  and  terminol-ogy.Epilepsia,42(9), 1212–1218. doi:10.1046/j.1528-1157.2001.22001.x\n",
        "\n",
        "5. Paz,  J.  T.,  &  Huguenard,  J.  R.  (2014).  Optogenetics  andepilepsy: Past, present and future.Epilepsy Currents,15(1), 34–38. doi:10.5698/1535-7597-15.1.34\n",
        "\n",
        "6. Holmes,  M.  D.,  Brown,  M.,  &  Tucker,  D.  M.  (2004).  Are\"generalized\" seizures truly generalized? Evidence oflocalized mesial frontal and frontopolar discharges inabsence.Epilepsia,45(12), 1568–1579. doi:10.1111/j.0013-9580.2004.23204.x\n",
        "\n",
        "7. Spencer, S. (2002). Neural Networks in human epilepsy: ev-idence  of  and  implications  for  treatment.Epilepsia,43(3), 219–227\n",
        "\n",
        "8. Bidwell2015\n",
        "\n",
        "9. Varsavsky, A., Mareels, I., & Cook, M. (2011). EEG Generation and Measurement. InEpileptic seizures and theeeg: Measurement, models, detection and prediction(Chap. 2, p. 337). doi:doi:10.1201/b10459-3\n",
        "\n",
        "10. Wilson,  S.  B.,  Scheuer,  M.  L.,  Plummer,  C.,  Young,  B.,& Pacia, S. (2003). Seizure detection: Correlation ofhuman  experts.Clinical Neurophysiology,114(11),2156–2164. doi:10.1016/S1388-2457(03)00212-8\n",
        "\n",
        "11. NICE\n",
        "\n",
        "12. Kaplan2000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFJYUegimt39"
      },
      "source": [
        "# Environment Set-up\n",
        "\n",
        "First lets set up our notebook environment with the packages we need. If you are following along on Google Colab, then this will install the packages you will need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SEhm7rqmxUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e841645-e9c3-4695-a391-359d4d48084f"
      },
      "source": [
        "!pip install matplotlib pandas numpy scipy seaborn mne\n",
        "!pip install beautifulsoup4 requests wget\n",
        "!pip install h5py tables kaggle\n",
        "!pip install wfdb pyEDFlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.1)\n",
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f7/2bf5de3fad42b66d00ee27539bc3be0260b4e66fdecc12f740cdf2daf2e7/mne-0.23.0-py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzeDeku7naEK"
      },
      "source": [
        "This creates a class called color which can be used to change the appearance of strings printed in the outputs of each cell. I like using it for nicer outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4oE6l1Lna9l"
      },
      "source": [
        "# colours for printing outputs\n",
        "class color:\n",
        "   PURPLE = '\\033[95m'\n",
        "   CYAN = '\\033[96m'\n",
        "   DARKCYAN = '\\033[36m'\n",
        "   BLUE = '\\033[94m'\n",
        "   GREEN = '\\033[92m'\n",
        "   YELLOW = '\\033[93m'\n",
        "   RED = '\\033[91m'\n",
        "   BOLD = '\\033[1m'\n",
        "   UNDERLINE = '\\033[4m'\n",
        "   END = '\\033[0m'\n",
        "  \n",
        "print(color.BOLD+color.UNDERLINE+'Title'+color.END)\n",
        "print('Hello World')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2Zs4Zkfnh5s"
      },
      "source": [
        "Lets create a function to list all the files/directories it finds in a location and save them to a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMocaNKonk2S"
      },
      "source": [
        "import glob            # for file locations\n",
        "import pprint          # for pretty printing\n",
        "import re\n",
        "\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "def file_list(folder_path, output=False):\n",
        "    # create an empty list\n",
        "    file_list = []\n",
        "    # for file name in the folder path...\n",
        "    for filename in glob.glob(folder_path):\n",
        "        # ... append it to the list\n",
        "        file_list.append(filename)\n",
        "        \n",
        "    # sort alphabetically\n",
        "    file_list.sort()\n",
        "    \n",
        "    # Output\n",
        "    if output:\n",
        "        print(str(len(file_list)) + \" files found\")\n",
        "        pp.pprint(file_list)\n",
        "    \n",
        "    return file_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YrXKngLk3MQ"
      },
      "source": [
        "# CHB-MIT Scalp EEG Database Pre Vs Ictal\n",
        "\n",
        "The CHB-MIT dataset<sup>1</sup>, consists of records from 23 patients; with one case (chb21) taken from the same patient (chb01) 1.5 years later. The dataset was collected by investigators at the Children’s Hospital Boston and Massachusetts Institute of Technology (MIT). The median length of collection was for 36 hours with small gaps between records each hour due to hardware limitations.\n",
        "\n",
        "The data contains 198 seizures of various types (focal, lateral, and generalised seizures). All signals were recorded at 256 samples per second with most files containing 23 EEG signals positioned using the International 10-20 system (as we will see later). \n",
        "\n",
        "This dataset is one of the most prominent datasets in the literature, as it provides long, continuous recordings for each patient, allowing for both patient specific and patient general models to be developed and tested.\n",
        "\n",
        "\n",
        "| Subject   | Age/Gender | Seizure Events | Total Ictal Time (secs) | Total Inter-ictal Time (secs) |\n",
        "|-----------|------------|----------------|------------------|----------------------|\n",
        "| chb01/chb21 | 11, 13 (F) | 11 | 641  | 263461 |\n",
        "| chb02       | 11 (M)     | 3  | 172  | 126751 |\n",
        "| chb03       | 14 (F)     | 7  | 402  | 136366 |\n",
        "| chb04       | 22 (M)     | 4  | 378  | 561414 |\n",
        "| chb05       | 7 (F)      | 5  | 558  | 139813 |\n",
        "| chb06       | 1.5 (F)    | 10 | 153  | 240075 |\n",
        "| chb07       | 14.5 (F)   | 3  | 325  | 241044 |\n",
        "| chb08       | 3.5 (M)    | 5  | 919  | 71084  |\n",
        "| chb09       | 10 (F)     | 4  | 276  | 244043 |\n",
        "| chb10       | 3 (M)      | 7  | 447  | 179612 |\n",
        "| chb11       | 12 (F)     | 3  | 806  | 124416 |\n",
        "| chb12       | 2 (F)      | 27 | 989  | 73466  |\n",
        "| chb13       | 3 (F)      | 12 | 535  | 118232 |\n",
        "| chb14       | 9 (F)      | 8  | 169  | 93405  |\n",
        "| chb15       | 16 (M)     | 20 | 1992 | 142004 |\n",
        "| chb16       | 7 (F)      | 10 | 84   | 68297  |\n",
        "| chb17       | 12 (F)     | 3  | 293  | 75310  |\n",
        "| chb18       | 18 (F)     | 6  | 317  | 127932 |\n",
        "| chb19       | 19 (F)     | 3  | 236  | 107480 |\n",
        "| chb20       | 6 (F)      | 8  | 294  | 99043  |\n",
        "| chb22       | 9 (F)      | 3  | 204  | 111376 |\n",
        "| chb23       | 6 (F)      | 7  | 424  | 95177  |\n",
        "| chb24       | NR (NR)    | 16 | 511  | 76134  |\n",
        "| **Total**   | -          | **185**| **11125**| **3515935**|\n",
        "\n",
        "**NOTE**\n",
        "- You may have noticed that in the table above it actually only totals to 185 seizures. Thats because the method I use to load the data into Python does not work on a select few files. This reduces the number of seizure events from 40 to 27 in patient 12 by not including files 27, 28, and 29.\n",
        "\n",
        "---\n",
        "1. Shoeb2009"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3nQabDFgTJG"
      },
      "source": [
        "## Data Information\n",
        "The dataset is stored on Physionet which has some helpful tools to access the data. We are going to use one such package (wfdb) to get a list of the records in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnBZ4HacSgR4"
      },
      "source": [
        "import wfdb \n",
        "\n",
        "dbs = wfdb.get_dbs()\n",
        "\n",
        "records_list = wfdb.io.get_record_list('chbmit', records='all')\n",
        "records_list[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiaNHSo4UTpe"
      },
      "source": [
        "Using the above, lets get a list of the unique directory names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb0Nwi22UVSX"
      },
      "source": [
        "part_codes = sorted(list(set([record.split('/')[0] for record in records_list])))\n",
        "part_codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSRValh-UX1M"
      },
      "source": [
        "Each patient has an information file associate with it. Lets load one in and have a look at how it looks before we parse it into something more useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUOKoJ7NUaC_"
      },
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "def get_content(part_code):\n",
        "  url = \"https://physionet.org/physiobank/database/chbmit/\"+part_code+'/'+part_code+'-summary.txt'\n",
        "  filename = \"./chbmit.txt\"\n",
        "\n",
        "  urlretrieve(url,filename)\n",
        "\n",
        "  # read the file into a list\n",
        "  with open(filename, encoding='UTF-8') as f:\n",
        "      # read all the document into a list of strings (each line a new string)\n",
        "      content = f.readlines()\n",
        "      os.remove(filename)\n",
        "\n",
        "  return content\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KY-Eo4elTfu"
      },
      "source": [
        "get_content(part_codes[0])#[6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIn_QjsNbXTA"
      },
      "source": [
        "Taking the above, the below function below just parses this file up into a Python dictionary format we can use later. See the output for an example of what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Q5Fr5OUe7K"
      },
      "source": [
        "import re\n",
        "part_info_dict = {}\n",
        "filenames_s = []\n",
        "\n",
        "def info_dict(content):\n",
        "  \n",
        "  line_nos=len(content)\n",
        "  line_no=1\n",
        "\n",
        "  channels = []\n",
        "  file_name = []\n",
        "  file_info_dict={}\n",
        "\n",
        "  for line in content:\n",
        "\n",
        "    # if there is Channel in the line...\n",
        "    if re.findall('Channel \\d+', line):\n",
        "      # split the line into channel number and channel reference\n",
        "      channel = line.split(': ')\n",
        "      # get the channel reference and remove any new lines\n",
        "      channel = channel[-1].replace(\"\\n\", \"\")\n",
        "      # put into the channel list\n",
        "      channels.append(channel)\n",
        "\n",
        "    # if the line is the file name\n",
        "    elif re.findall('File Name', line):\n",
        "      # if there is already a file_name\n",
        "      if file_name and file_info_dict['Seizures Window']:\n",
        "        # flush the current file info to it\n",
        "        part_info_dict[file_name] = file_info_dict\n",
        "\n",
        "      # get the file name\n",
        "      file_name = re.findall('\\w+\\d+_\\d+|\\w+\\d+\\w+_\\d+', line)[0]\n",
        "\n",
        "      file_info_dict = {}\n",
        "      # put the channel list in the file info dict and remove duplicates\n",
        "      file_info_dict['Channels'] = list(set(channels))\n",
        "      # reset the rest of the options\n",
        "      file_info_dict['Start Time'] = ''\n",
        "      file_info_dict['End Time'] = ''\n",
        "      file_info_dict['Seizures Window'] = []\n",
        "\n",
        "    # if the line is about the file start time\n",
        "    elif re.findall('File Start Time', line):\n",
        "      # get the start time\n",
        "      file_info_dict['Start Time'] = re.findall('\\d+:\\d+:\\d+', line)[0]\n",
        "\n",
        "    # if the line is about the file end time\n",
        "    elif re.findall('File End Time', line):\n",
        "      # get the start time\n",
        "      file_info_dict['End Time'] = re.findall('\\d+:\\d+:\\d+', line)[0]\n",
        "\n",
        "    elif re.findall('Seizure Start Time|Seizure End Time|Seizure \\d+ Start Time|Seizure \\d+ End Time', line):\n",
        "      file_info_dict['Seizures Window'].append(int(re.findall('\\d+', line)[-1]))\n",
        "\n",
        "    # if last line in the list...\n",
        "    if line_no == line_nos and file_info_dict['Seizures Window']:\n",
        "      # flush the file info to it\n",
        "      part_info_dict[file_name] = file_info_dict\n",
        "\n",
        "    line_no+=1\n",
        "    \n",
        "        \n",
        "for part_code in part_codes:\n",
        "  content = get_content(part_code)\n",
        "  info_dict(content)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9LnexSfn3iO"
      },
      "source": [
        "print(color.BOLD+color.UNDERLINE+'part_info_dict'+color.END)\n",
        "display(part_info_dict['chb01_03'])\n",
        "print(color.UNDERLINE+'\\nPart Keys'+color.END)\n",
        "print(part_info_dict[list(part_info_dict.keys())[0]].keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYeV9uGOPrEo"
      },
      "source": [
        "As can be seen below there is a common set of channels found in ALL patients, but there are also some channels only found in individual patients. This is because sometimes channels were swapped during recording for others. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozlKYo5OPs9-"
      },
      "source": [
        "import pandas as pd     # dataframes\n",
        "import re\n",
        "\n",
        "all_channels = []\n",
        "\n",
        "for key in part_info_dict.keys():\n",
        "    all_channels.extend(part_info_dict[key]['Channels'])\n",
        "    \n",
        "# turn the list into a pandas series\n",
        "all_channels = pd.Series(all_channels)\n",
        "\n",
        "# count how many times the channels appear in each participant\n",
        "channel_counts = all_channels.value_counts()\n",
        "channel_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nql0DxtDPyvG"
      },
      "source": [
        "To deal with the fact some channels are only found in individual patients, I tend to keep channels found in all the patients. This makes generalising models across patients easier, however if you are only training models to identify a particular patients seizures you wouldnt need to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcTGLlQDP062"
      },
      "source": [
        "threshold = len(part_info_dict.keys())\n",
        "channel_keeps = list(channel_counts[channel_counts >= threshold].index)\n",
        "channel_keeps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhmv3k9wU5em"
      },
      "source": [
        "## Load Data\n",
        "Lets now load in some example data. First lets choose a file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbHLPFjup5gO"
      },
      "source": [
        "records_list_new = []\n",
        "\n",
        "for record in records_list:\n",
        "  try :\n",
        "    part_info_dict[record.split('/')[1].split('.')[0]]\n",
        "  except : \n",
        "    #print('Nope : ',record)\n",
        "    continue\n",
        "  if part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][1] - part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0] >= 30*2:\n",
        "    records_list_new.append(record)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQuK5qMqmgA"
      },
      "source": [
        "len(records_list_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERu5mKcXa7lM"
      },
      "source": [
        "EXAMPLE_FILE = records_list_new[0]\n",
        "EXAMPLE_ID = EXAMPLE_FILE.split('/')[1].split('.')[0]\n",
        "EXAMPLE_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBqLCQ8Esqs0"
      },
      "source": [
        "sub_freq = dict()\n",
        "\n",
        "for record in records_list_new:\n",
        "  if record.split('/')[1].split('.')[0][:-3] in sub_freq:\n",
        "    sub_freq[record.split('/')[1].split('.')[0][:-3]] += 1\n",
        "  else:\n",
        "    sub_freq[record.split('/')[1].split('.')[0][:-3]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2-GE7HRtcHy"
      },
      "source": [
        "# sub_freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AM6_jPhuXlL"
      },
      "source": [
        "records_list_new_new = []\n",
        "count = 0\n",
        "last = ''\n",
        "\n",
        "for record in records_list_new:\n",
        "  sub_f = sub_freq[record.split('/')[1].split('.')[0][:-3]]\n",
        "  sub = record.split('/')[1].split('.')[0][:-3]\n",
        "  if sub_f >= 3 and count < 3: \n",
        "    records_list_new_new.append(record)\n",
        "    count += 1\n",
        "    last = sub\n",
        "  elif sub_f >= 3 and sub != last:\n",
        "    count = 0\n",
        "    records_list_new_new.append(record)\n",
        "    count += 1\n",
        "    last = sub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw9hZwPSwLbY"
      },
      "source": [
        "sub_freq2 = dict()\n",
        "\n",
        "for record in records_list_new_new:\n",
        "  if record.split('/')[1].split('.')[0][:-3] in sub_freq2:\n",
        "    sub_freq2[record.split('/')[1].split('.')[0][:-3]] += 1\n",
        "  else:\n",
        "    sub_freq2[record.split('/')[1].split('.')[0][:-3]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv6_UyvJwRFe"
      },
      "source": [
        "sub_freq2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbBWMtMorPTz"
      },
      "source": [
        "max = 0\n",
        "min = 1000000\n",
        "for record in records_list_new_new:\n",
        "  temp = part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0] #- part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0]\n",
        "  if temp > max:\n",
        "    max = temp\n",
        "  if temp < min:\n",
        "    min = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgJPUWMcr36W"
      },
      "source": [
        "max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEUIfSear5Xa"
      },
      "source": [
        "min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef1A2c7LcBOf"
      },
      "source": [
        "Now using the function below I can download the data and then load it into a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC7bQe41U766"
      },
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyedflib\n",
        "\n",
        "def data_load(file, selected_channels=[]):\n",
        "\n",
        "  try: \n",
        "    url = \"https://physionet.org/physiobank/database/chbmit/\"+file\n",
        "    filename = \"./chbmit.edf\"\n",
        "\n",
        "    urlretrieve(url,filename)\n",
        "    # use the reader to get an EdfReader file\n",
        "    f = pyedflib.EdfReader(filename)\n",
        "    os.remove(filename)\n",
        "    \n",
        "    # get a list of the EEG channels\n",
        "    if len(selected_channels) == 0:\n",
        "      selected_channels = f.getSignalLabels()\n",
        "\n",
        "    # get the names of the signals\n",
        "    channel_names = f.getSignalLabels()\n",
        "    # get the sampling frequencies of each signal\n",
        "    channel_freq = f.getSampleFrequencies()\n",
        "\n",
        "    # make an empty file of 0's\n",
        "    sigbufs = np.zeros((f.getNSamples()[0],len(selected_channels)))\n",
        "    # for each of the channels in the selected channels\n",
        "    for i, channel in enumerate(selected_channels):\n",
        "      # add the channel data into the array\n",
        "      sigbufs[:, i] = f.readSignal(channel_names.index(channel))\n",
        "    \n",
        "    # turn to a pandas df and save a little space\n",
        "    df = pd.DataFrame(sigbufs, columns = selected_channels).astype('float32')\n",
        "    \n",
        "    # get equally increasing numbers upto the length of the data depending\n",
        "    # on the length of the data divided by the sampling frequency\n",
        "    index_increase = np.linspace(0,\n",
        "                                 len(df)/channel_freq[0],\n",
        "                                 len(df), endpoint=False)\n",
        "\n",
        "    # round these to the lowest nearest decimal to get the seconds\n",
        "    seconds = np.floor(index_increase).astype('uint16')\n",
        "\n",
        "    # make a column the timestamp\n",
        "    df['Time'] = seconds\n",
        "\n",
        "    # make the time stamp the index\n",
        "    #df = df.set_index('Time')\n",
        "\n",
        "    # name the columns as channel\n",
        "    #df.columns.name = 'Channel'\n",
        "\n",
        "    return df, channel_freq[0]\n",
        "\n",
        "  except:\n",
        "    OSError\n",
        "    return pd.DataFrame(), None\n",
        "\n",
        "\n",
        "raw_data, freq = data_load(EXAMPLE_FILE, channel_keeps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1gmhXdax66t"
      },
      "source": [
        "channel_keeps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBQHecHMoPYX"
      },
      "source": [
        "display(raw_data)#[channel_keeps[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwOE7kAExGG0"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x_data = np.zeros((len(sub_freq2), 18, 256*20, len(channel_keeps)))\n",
        "y_data = np.zeros((len(sub_freq2), 18))\n",
        "\n",
        "countt = 0 \n",
        "sub_count = 0\n",
        "\n",
        "for record in tqdm(records_list_new_new):\n",
        "  if countt >= 3:\n",
        "    countt = 0\n",
        "    sub_count += 1\n",
        "  raw_data, freq = data_load(record, channel_keeps)\n",
        "  if freq != 256:\n",
        "    print('ERROR')\n",
        "    break\n",
        "  # seizure\n",
        "  mid_s = int((part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][1] - part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0])/2) - 10\n",
        "  start_s = part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0]\n",
        "  end_s = part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][1] - 20\n",
        "  # No seizure\n",
        "  start = 0\n",
        "  mid = int(part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0]/2 ) - 10\n",
        "  end = part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0] - 1 - 20\n",
        "\n",
        "  for i, channel in enumerate(channel_keeps):\n",
        "    # No seizure\n",
        "    x_data[sub_count, 0 + 6*countt, :, i] = np.array(raw_data[raw_data['Time'].between(start+1,start+20)][channel].tolist())\n",
        "    y_data[sub_count, 0 + 6*countt] = 0\n",
        "    x_data[sub_count, 1 + 6*countt, :, i] = np.array(raw_data[raw_data['Time'].between(mid+1,mid+20)][channel].tolist())\n",
        "    y_data[sub_count, 1 + 6*countt] = 0\n",
        "    x_data[sub_count, 2 + 6*countt, :, i] = np.array(raw_data[raw_data['Time'].between(end+1,end+20)][channel].tolist())\n",
        "    y_data[sub_count, 2 + 6*countt] = 0\n",
        "    # seizure\n",
        "    x_data[sub_count, 3 + 6*countt, :, i] = np.array(raw_data[raw_data['Time'].between(start_s+1,start_s+20)][channel].tolist())\n",
        "    y_data[sub_count, 3 + 6*countt] = 1\n",
        "    x_data[sub_count, 4 + 6*countt, :, i] = np.array(raw_data[raw_data['Time'].between(mid_s+1,mid_s+20)][channel].tolist())\n",
        "    y_data[sub_count, 4 + 6*countt] = 1\n",
        "    x_data[sub_count, 5 + 6*countt, :, i] = np.array(raw_data[raw_data['Time'].between(end_s+1,end_s+20)][channel].tolist())\n",
        "    y_data[sub_count, 5 + 6*countt] = 1\n",
        "\n",
        "  countt += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo7DHRqH8Gy8"
      },
      "source": [
        "x_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiDGWK_O8O9F"
      },
      "source": [
        "y_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G47XZ52FvAsT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJC9ODH66uG3"
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/EMOTION/VQVAE-trans/Trans-checkpoints-py/x_data_ss.pkl', 'wb') as filepath:\n",
        "      pickle.dump(x_data, filepath)\n",
        "with open('/content/drive/MyDrive/EMOTION/VQVAE-trans/Trans-checkpoints-py/y_data_ss.pkl', 'wb') as filepath:\n",
        "      pickle.dump(y_data, filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9VvcAa7-FTQ"
      },
      "source": [
        "sub_count "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlDaMstFaT7l"
      },
      "source": [
        "## Plot Data\n",
        "\n",
        "Now lets plot the data. We will use the dictionary we made earlier to mark an annotation as to where the seizures are in the record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoVoBNJ-auOC"
      },
      "source": [
        "def mne_object(data, freq, events = None):\n",
        "  # create an mne info file with meta data about the EEG\n",
        "  info = mne.create_info(ch_names=list(data.columns), \n",
        "                         sfreq=freq, \n",
        "                         ch_types=['eeg']*data.shape[-1])\n",
        "  \n",
        "  # data needs to be in volts rather than in microvolts\n",
        "  data = data.apply(lambda x: x*1e-6)\n",
        "  # transpose the data\n",
        "  data_T = data.transpose()\n",
        "  \n",
        "  # create raw mne object\n",
        "  raw = mne.io.RawArray(data_T, info)\n",
        "\n",
        "  if events:\n",
        "    start_times = np.array(events[::2])\n",
        "    end_times = np.array(events[1::2])\n",
        "    anno_length = end_times-start_times\n",
        "    event_name = np.array(['Ictal']*len(anno_length))\n",
        "\n",
        "    raw.set_annotations(mne.Annotations(start_times,\n",
        "                                      anno_length,\n",
        "                                      event_name))\n",
        "\n",
        "  return raw\n",
        "\n",
        "mne_data = mne_object(raw_data, freq, part_info_dict[EXAMPLE_ID]['Seizures Window'])\n",
        "\n",
        "\n",
        "mne_data.plot(start = 50, \n",
        "              duration = 30, **plot_kwargs);\n",
        "\n",
        "seiz_start_time = part_info_dict[EXAMPLE_ID]['Seizures Window'][0]\n",
        "mne_data.plot(start = seiz_start_time, \n",
        "              duration = 30, **plot_kwargs);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQUKzBTdbPY"
      },
      "source": [
        "Before we look at random segments again, lets take a second to look at the electrode placement. This is because this is the first *extracranial* dataset (meaning the electrodes are not implanted under the scalp).\n",
        "\n",
        "Scalp EEG is typically gained through placing 21-256 Ag/AgCl electrodes on the scalp, to enable the measurement of the electrical potential between spatially different electrodes. One electrode is dedicated as a *reference* during recording and another as a *ground*. The terms “ground” and “reference” are sometimes used interchangeably, although they refer to separate processes. \n",
        "\n",
        "**Ground Electrode**. \n",
        "A ground electrode is a common reference for the system voltage that aims to cancel out the common-mode interference that occurs from the body naturally picking up electromagnetic interference; particularly around 50/60Hz due to power lines. Unless recording takes place in a Faraday cage, this interference often needs to be filtered out during pre-processing (see next notebook) if not already conducted at time of recording by the amplifier. The ground electrode can be placed anywhere on the body, although the forehead or the ear are the most common<sup>1</sup>. \n",
        "\n",
        "**Reference Electrode**. \n",
        "A reference electrode aims to remove unspecific brain activity by representing the electrical potential between an active electrode of interest and a relatively inactive reference. A reference electrode is also still affected by global voltage changes as it is collected against the signal ground. Referencing can be done either by using a physical reference electrode placed on the earlobe, using any electrode during recording and later re-referencing electrodes to the average output of all electrodes, or by measuring potential between two active electrodes (bipolar recording)<sup>2</sup>. The combination of an active electrode with a reference and a ground creates a *channel*, and the general configuration of these channels are called a *montage*.\n",
        "\n",
        "These channels here are using a bi-polar montage. For ease of plotting, we will change their names to only be the first channel.\n",
        "\n",
        "---\n",
        "\n",
        "1. Light2010\n",
        "\n",
        "2. Varsavsky2011\n",
        "\n",
        "3. Teplan2002"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC7JtssseR4G"
      },
      "source": [
        "replace_dict = {}\n",
        "drop_list = []\n",
        "# for the channel names in the data...\n",
        "for channel_name in mne_data.info['ch_names']:\n",
        "    # get the name to change too\n",
        "    name_change = re.findall('\\w+',channel_name)[0].title()\n",
        "    # check if it is already in the change list\n",
        "    if name_change in list(replace_dict.values()):\n",
        "        drop_list.append(channel_name)\n",
        "    else:\n",
        "        # if its not already there get the origional name and what we want to \n",
        "        # change it to\n",
        "        replace_dict[channel_name] = name_change\n",
        "\n",
        "# drop the ones that would be repeats\n",
        "mne_data.drop_channels(drop_list)\n",
        "# rename the channels\n",
        "mne_data.rename_channels(replace_dict)\n",
        "# set the standard montage\n",
        "mne_data.set_montage('standard_1020')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWs1XrGnc5BI"
      },
      "source": [
        "Now we have set the names and montage lets plot it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI5aN3kQfxAd"
      },
      "source": [
        "mne_data.plot_sensors(kind='topomap', show_names=True, to_sphere=True);\n",
        "fig = mne_data.plot_sensors(kind='3d', show_names=True, show=False)\n",
        "fig = fig.gca().view_init(azim=70, elev=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KInYoyMDltPk"
      },
      "source": [
        "EEG has more than just temporal (changes over time) information, it has spatial as well. To demonstate, lets look at how the signal changes over the head before and during a seizure. \n",
        "\n",
        "We will go into different ways of breaking a signal down in more detail in the next notebook, so don't worry if you are not familiar with the welch method I use here. The basic take away is that there is generally more going on!\n",
        "\n",
        "**NOTES**\n",
        "- if you are familiar with the welch method we are just looking at the average power spectral density between 1-40Hz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaQtk5Fzl99h"
      },
      "source": [
        "from scipy import signal\n",
        "def ave_freq(data):\n",
        "    win = 4 * freq\n",
        "    freqs, psd = signal.welch(data, freq, nperseg=win, scaling='spectrum')\n",
        "    #print(freqs[4:160])\n",
        "    return psd[:,4:160].mean(1)\n",
        "\n",
        "inter_array = mne_data[:, 50*freq:80*freq][0]\n",
        "ictal_array = mne_data[:, (seiz_start_time*freq):(seiz_start_time*freq)+30*freq][0]\n",
        "topo_df = pd.DataFrame([ave_freq(inter_array),ave_freq(ictal_array)], index=['inter', 'ictal'])\n",
        "\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
        "\n",
        "axs = axs.flatten()\n",
        "for i, data_class in enumerate(topo_df.T):\n",
        "    topo, cn = mne.viz.plot_topomap(topo_df.loc[data_class],\n",
        "                                    mne_data.info,\n",
        "                                    show=False,\n",
        "                                    sensors=False,\n",
        "                                    names=mne_data.info['ch_names'], \n",
        "                                    show_names=True,\n",
        "                                    axes = axs[i],\n",
        "                                    vmin = topo_df.values.min(),\n",
        "                                    vmax = topo_df.values.max())\n",
        "    axs[i].set_title(data_class)\n",
        "    \n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJc6cPp7dYcY"
      },
      "source": [
        "Now, as we have done with the other datasets, lets randomly plot different parts of the data to see more examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvF2drumw81o"
      },
      "source": [
        "files_with_seizures = []\n",
        "for file_id in part_info_dict:\n",
        "    # if there is something in the seizure window\n",
        "    if part_info_dict[file_id]['Seizures Window']:\n",
        "        files_with_seizures.append(file_id)\n",
        "\n",
        "sampled_file = random.sample(files_with_seizures, 1)[0]\n",
        "sampled_file_path = sampled_file.split('_')[0]+'/'+sampled_file+'.edf'\n",
        "raw_data, freq = data_load(sampled_file_path, channel_keeps)\n",
        "mne_data = mne_object(raw_data, freq, part_info_dict[sampled_file]['Seizures Window'])\n",
        "\n",
        "print(color.BOLD+color.UNDERLINE+sampled_file+color.END)\n",
        "\n",
        "mne_data.plot(start = 50, \n",
        "              duration = 30, **plot_kwargs);\n",
        "\n",
        "mne_data.plot(start = part_info_dict[sampled_file]['Seizures Window'][0], \n",
        "              duration = 30, **plot_kwargs);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLBL6SGJoNkH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlxLML4NLmHf"
      },
      "source": [
        "# CHB-MIT Scalp EEG Database Inter Vs Ictal\n",
        "\n",
        "The CHB-MIT dataset<sup>1</sup>, consists of records from 23 patients; with one case (chb21) taken from the same patient (chb01) 1.5 years later. The dataset was collected by investigators at the Children’s Hospital Boston and Massachusetts Institute of Technology (MIT). The median length of collection was for 36 hours with small gaps between records each hour due to hardware limitations.\n",
        "\n",
        "The data contains 198 seizures of various types (focal, lateral, and generalised seizures). All signals were recorded at 256 samples per second with most files containing 23 EEG signals positioned using the International 10-20 system (as we will see later). \n",
        "\n",
        "This dataset is one of the most prominent datasets in the literature, as it provides long, continuous recordings for each patient, allowing for both patient specific and patient general models to be developed and tested.\n",
        "\n",
        "\n",
        "| Subject   | Age/Gender | Seizure Events | Total Ictal Time (secs) | Total Inter-ictal Time (secs) |\n",
        "|-----------|------------|----------------|------------------|----------------------|\n",
        "| chb01/chb21 | 11, 13 (F) | 11 | 641  | 263461 |\n",
        "| chb02       | 11 (M)     | 3  | 172  | 126751 |\n",
        "| chb03       | 14 (F)     | 7  | 402  | 136366 |\n",
        "| chb04       | 22 (M)     | 4  | 378  | 561414 |\n",
        "| chb05       | 7 (F)      | 5  | 558  | 139813 |\n",
        "| chb06       | 1.5 (F)    | 10 | 153  | 240075 |\n",
        "| chb07       | 14.5 (F)   | 3  | 325  | 241044 |\n",
        "| chb08       | 3.5 (M)    | 5  | 919  | 71084  |\n",
        "| chb09       | 10 (F)     | 4  | 276  | 244043 |\n",
        "| chb10       | 3 (M)      | 7  | 447  | 179612 |\n",
        "| chb11       | 12 (F)     | 3  | 806  | 124416 |\n",
        "| chb12       | 2 (F)      | 27 | 989  | 73466  |\n",
        "| chb13       | 3 (F)      | 12 | 535  | 118232 |\n",
        "| chb14       | 9 (F)      | 8  | 169  | 93405  |\n",
        "| chb15       | 16 (M)     | 20 | 1992 | 142004 |\n",
        "| chb16       | 7 (F)      | 10 | 84   | 68297  |\n",
        "| chb17       | 12 (F)     | 3  | 293  | 75310  |\n",
        "| chb18       | 18 (F)     | 6  | 317  | 127932 |\n",
        "| chb19       | 19 (F)     | 3  | 236  | 107480 |\n",
        "| chb20       | 6 (F)      | 8  | 294  | 99043  |\n",
        "| chb22       | 9 (F)      | 3  | 204  | 111376 |\n",
        "| chb23       | 6 (F)      | 7  | 424  | 95177  |\n",
        "| chb24       | NR (NR)    | 16 | 511  | 76134  |\n",
        "| **Total**   | -          | **185**| **11125**| **3515935**|\n",
        "\n",
        "**NOTE**\n",
        "- You may have noticed that in the table above it actually only totals to 185 seizures. Thats because the method I use to load the data into Python does not work on a select few files. This reduces the number of seizure events from 40 to 27 in patient 12 by not including files 27, 28, and 29.\n",
        "\n",
        "---\n",
        "1. Shoeb2009"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAUjOirILmHp"
      },
      "source": [
        "## Data Information\n",
        "The dataset is stored on Physionet which has some helpful tools to access the data. We are going to use one such package (wfdb) to get a list of the records in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "729EWGl0LmHq"
      },
      "source": [
        "import wfdb \n",
        "\n",
        "dbs = wfdb.get_dbs()\n",
        "\n",
        "records_list = wfdb.io.get_record_list('chbmit', records='all')\n",
        "records_list[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "596DJin7OubM"
      },
      "source": [
        "records_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfHa7hLTLmHr"
      },
      "source": [
        "Using the above, lets get a list of the unique directory names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AHy6Xc6LmHr"
      },
      "source": [
        "part_codes = sorted(list(set([record.split('/')[0] for record in records_list])))\n",
        "part_codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI2cVUvzLmHs"
      },
      "source": [
        "Each patient has an information file associate with it. Lets load one in and have a look at how it looks before we parse it into something more useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlYQEWQJLmHs"
      },
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "def get_content(part_code):\n",
        "  url = \"https://physionet.org/physiobank/database/chbmit/\"+part_code+'/'+part_code+'-summary.txt'\n",
        "  filename = \"./chbmit.txt\"\n",
        "\n",
        "  urlretrieve(url,filename)\n",
        "\n",
        "  # read the file into a list\n",
        "  with open(filename, encoding='UTF-8') as f:\n",
        "      # read all the document into a list of strings (each line a new string)\n",
        "      content = f.readlines()\n",
        "      os.remove(filename)\n",
        "\n",
        "  return content\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU3CNI0-LmHs"
      },
      "source": [
        "get_content(part_codes[23])#[6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTkdu-TVLmHs"
      },
      "source": [
        "Taking the above, the below function below just parses this file up into a Python dictionary format we can use later. See the output for an example of what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElWLR_agLmHs"
      },
      "source": [
        "import re\n",
        "part_info_dict = {}\n",
        "\n",
        "def info_dict(content):\n",
        "  \n",
        "  line_nos=len(content)\n",
        "  line_no=1\n",
        "  count = 0\n",
        "\n",
        "  channels = []\n",
        "  file_name = []\n",
        "  file_info_dict={}\n",
        "\n",
        "  for line in content:\n",
        "\n",
        "    # if there is Channel in the line...\n",
        "    if re.findall('Channel \\d+', line):\n",
        "      # split the line into channel number and channel reference\n",
        "      channel = line.split(': ')\n",
        "      # get the channel reference and remove any new lines\n",
        "      channel = channel[-1].replace(\"\\n\", \"\")\n",
        "      # put into the channel list\n",
        "      channels.append(channel)\n",
        "\n",
        "    # if the line is the file name\n",
        "    elif re.findall('File Name', line):\n",
        "      # if there is already a file_name\n",
        "      if file_name:\n",
        "        # flush the current file info to it\n",
        "        if file_info_dict['Seizures Window'] or not(count):\n",
        "          count = 1\n",
        "          part_info_dict[file_name] = file_info_dict\n",
        "\n",
        "      # get the file name\n",
        "      file_name = re.findall('\\w+\\d+_\\d+|\\w+\\d+\\w+_\\d+', line)[0]\n",
        "\n",
        "      file_info_dict = {}\n",
        "      # put the channel list in the file info dict and remove duplicates\n",
        "      file_info_dict['Channels'] = list(set(channels))\n",
        "      # reset the rest of the options\n",
        "      file_info_dict['Start Time'] = ''\n",
        "      file_info_dict['End Time'] = ''\n",
        "      file_info_dict['Seizures Window'] = []\n",
        "\n",
        "    # if the line is about the file start time\n",
        "    elif re.findall('File Start Time', line):\n",
        "      # get the start time\n",
        "      file_info_dict['Start Time'] = re.findall('\\d+:\\d+:\\d+', line)[0]\n",
        "\n",
        "    # if the line is about the file end time\n",
        "    elif re.findall('File End Time', line):\n",
        "      # get the start time\n",
        "      file_info_dict['End Time'] = re.findall('\\d+:\\d+:\\d+', line)[0]\n",
        "\n",
        "    elif re.findall('Seizure Start Time|Seizure End Time|Seizure \\d+ Start Time|Seizure \\d+ End Time', line):\n",
        "      file_info_dict['Seizures Window'].append(int(re.findall('\\d+', line)[-1]))\n",
        "\n",
        "    # if last line in the list...\n",
        "    if line_no == line_nos:\n",
        "      # flush the file info to it\n",
        "      if file_info_dict['Seizures Window'] or not(count):\n",
        "          count = 1\n",
        "          part_info_dict[file_name] = file_info_dict\n",
        "\n",
        "    line_no+=1\n",
        "    \n",
        "        \n",
        "for part_code in part_codes:\n",
        "  content = get_content(part_code)\n",
        "  info_dict(content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxTVkutHLmHt"
      },
      "source": [
        "print(color.BOLD+color.UNDERLINE+'part_info_dict'+color.END)\n",
        "display(part_info_dict['chb24_13'])\n",
        "print(color.UNDERLINE+'\\nPart Keys'+color.END)\n",
        "print(part_info_dict[list(part_info_dict.keys())[0]].keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UkAJasdLz-u"
      },
      "source": [
        "# part_info_dict_new = dict()\n",
        "\n",
        "# for i in range(len(records_list)):\n",
        "#   filee1 = records_list[i].split('/')[1].split('.')[0]\n",
        "#   filee2 = records_list[i-1].split('/')[1].split('.')[0]\n",
        "#   #print(filee)\n",
        "#   try:\n",
        "#     num = int(records_list[i].split('/')[1].split('.')[0][-2:])\n",
        "#     num2 = int(records_list[i-1].split('/')[1].split('.')[0][-2:])\n",
        "#     check1 = part_info_dict[filee1]\n",
        "#     check2 = part_info_dict[filee2]\n",
        "#   except:\n",
        "#     continue\n",
        "#   if part_info_dict[filee1]['Seizures Window'] and num > 2:\n",
        "#     part_info_dict_new[filee2] = part_info_dict[filee2]\n",
        "#     part_info_dict_new[filee1] = part_info_dict[filee1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK4KmQQQSjk8"
      },
      "source": [
        "part_info_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0A_gNPLLmHt"
      },
      "source": [
        "As can be seen below there is a common set of channels found in ALL patients, but there are also some channels only found in individual patients. This is because sometimes channels were swapped during recording for others. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK-12vPbLmHt"
      },
      "source": [
        "import pandas as pd     # dataframes\n",
        "import re\n",
        "\n",
        "all_channels = []\n",
        "\n",
        "for key in part_info_dict.keys():\n",
        "    all_channels.extend(part_info_dict[key]['Channels'])\n",
        "    \n",
        "# turn the list into a pandas series\n",
        "all_channels = pd.Series(all_channels)\n",
        "\n",
        "# count how many times the channels appear in each participant\n",
        "channel_counts = all_channels.value_counts()\n",
        "channel_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FdOGaYoLmHt"
      },
      "source": [
        "To deal with the fact some channels are only found in individual patients, I tend to keep channels found in all the patients. This makes generalising models across patients easier, however if you are only training models to identify a particular patients seizures you wouldnt need to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnetsGneLmHu"
      },
      "source": [
        "threshold = len(part_info_dict.keys())\n",
        "channel_keeps = list(channel_counts[channel_counts >= threshold].index)\n",
        "channel_keeps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hflYheurLmHv"
      },
      "source": [
        "## Load Data\n",
        "Lets now load in some example data. First lets choose a file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIgNd230LmHw"
      },
      "source": [
        "records_list_new = []\n",
        "\n",
        "for record in records_list:\n",
        "  try :\n",
        "    part_info_dict[record.split('/')[1].split('.')[0]]\n",
        "  except : \n",
        "    #print('Nope : ',record)\n",
        "    continue\n",
        "  if not(part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window']):\n",
        "    records_list_new.append(record)\n",
        "  elif part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][1] - part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0] >= 30*2:\n",
        "    records_list_new.append(record)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UAVlmTcLmHw"
      },
      "source": [
        "len(records_list_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nv1_1IRLmHw"
      },
      "source": [
        "EXAMPLE_FILE = records_list_new[0]\n",
        "EXAMPLE_ID = EXAMPLE_FILE.split('/')[1].split('.')[0]\n",
        "EXAMPLE_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6WlWwPoLmHw"
      },
      "source": [
        "sub_freq = dict()\n",
        "\n",
        "for record in records_list_new:\n",
        "  if record.split('/')[1].split('.')[0][:-3] in sub_freq:\n",
        "    sub_freq[record.split('/')[1].split('.')[0][:-3]] += 1\n",
        "  else:\n",
        "    sub_freq[record.split('/')[1].split('.')[0][:-3]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a9q0O9vLmHx"
      },
      "source": [
        "sub_freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZAZKH_eLmHx"
      },
      "source": [
        "records_list_new_new = []\n",
        "count = 0\n",
        "last = ''\n",
        "\n",
        "for record in records_list_new:\n",
        "  sub_f = sub_freq[record.split('/')[1].split('.')[0][:-3]]\n",
        "  sub = record.split('/')[1].split('.')[0][:-3]\n",
        "  if sub_f >= 4 and count < 4: \n",
        "    records_list_new_new.append(record)\n",
        "    count += 1\n",
        "    last = sub\n",
        "  elif sub_f >= 4 and sub != last:\n",
        "    count = 0\n",
        "    records_list_new_new.append(record)\n",
        "    count += 1\n",
        "    last = sub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CsSau7CLmHx"
      },
      "source": [
        "sub_freq2 = dict()\n",
        "\n",
        "for record in records_list_new_new:\n",
        "  if record.split('/')[1].split('.')[0][:-3] in sub_freq2:\n",
        "    sub_freq2[record.split('/')[1].split('.')[0][:-3]] += 1\n",
        "  else:\n",
        "    sub_freq2[record.split('/')[1].split('.')[0][:-3]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svL2YlooLmHx"
      },
      "source": [
        "sub_freq2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5haAMqDLmHy"
      },
      "source": [
        "max = 0\n",
        "min = 1000000\n",
        "for record in records_list_new_new:\n",
        "  if not(part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window']):\n",
        "    continue\n",
        "  temp = part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0] #- part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0]\n",
        "  if temp > max:\n",
        "    max = temp\n",
        "  if temp < min:\n",
        "    min = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se-Pbj0BLmHy"
      },
      "source": [
        "max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7xFiuNNLmHz"
      },
      "source": [
        "min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmQugRxMLmHz"
      },
      "source": [
        "Now using the function below I can download the data and then load it into a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le5ZIX4MLmHz"
      },
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyedflib\n",
        "\n",
        "def data_load(file, selected_channels=[]):\n",
        "\n",
        "  try: \n",
        "    url = \"https://physionet.org/physiobank/database/chbmit/\"+file\n",
        "    filename = \"./chbmit.edf\"\n",
        "\n",
        "    urlretrieve(url,filename)\n",
        "    # use the reader to get an EdfReader file\n",
        "    f = pyedflib.EdfReader(filename)\n",
        "    os.remove(filename)\n",
        "    \n",
        "    # get a list of the EEG channels\n",
        "    if len(selected_channels) == 0:\n",
        "      selected_channels = f.getSignalLabels()\n",
        "\n",
        "    # get the names of the signals\n",
        "    channel_names = f.getSignalLabels()\n",
        "    # get the sampling frequencies of each signal\n",
        "    channel_freq = f.getSampleFrequencies()\n",
        "\n",
        "    # make an empty file of 0's\n",
        "    sigbufs = np.zeros((f.getNSamples()[0],len(selected_channels)))\n",
        "    # for each of the channels in the selected channels\n",
        "    for i, channel in enumerate(selected_channels):\n",
        "      # add the channel data into the array\n",
        "      sigbufs[:, i] = f.readSignal(channel_names.index(channel))\n",
        "    \n",
        "    # turn to a pandas df and save a little space\n",
        "    df = pd.DataFrame(sigbufs, columns = selected_channels).astype('float32')\n",
        "    \n",
        "    # get equally increasing numbers upto the length of the data depending\n",
        "    # on the length of the data divided by the sampling frequency\n",
        "    index_increase = np.linspace(0,\n",
        "                                 len(df)/channel_freq[0],\n",
        "                                 len(df), endpoint=False)\n",
        "\n",
        "    # round these to the lowest nearest decimal to get the seconds\n",
        "    seconds = np.floor(index_increase).astype('uint16')\n",
        "\n",
        "    # make a column the timestamp\n",
        "    df['Time'] = seconds\n",
        "\n",
        "    # make the time stamp the index\n",
        "    #df = df.set_index('Time')\n",
        "\n",
        "    # name the columns as channel\n",
        "    #df.columns.name = 'Channel'\n",
        "\n",
        "    return df, channel_freq[0]\n",
        "\n",
        "  except:\n",
        "    OSError\n",
        "    return pd.DataFrame(), None\n",
        "\n",
        "\n",
        "raw_data, freq = data_load(EXAMPLE_FILE, channel_keeps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS7VIr0zLmHz"
      },
      "source": [
        "channel_keeps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJTvc2DcLmHz"
      },
      "source": [
        "display(raw_data)#[channel_keeps[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5VH3PJ1LmH0"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x_data = np.zeros((len(sub_freq2), 18, 256*20, len(channel_keeps)))\n",
        "y_data = np.zeros((len(sub_freq2), 18))\n",
        "\n",
        "countt = 0 \n",
        "countt_s = 0\n",
        "sub_count = 0\n",
        "\n",
        "for record in tqdm(records_list_new_new):\n",
        "  if countt >= 4:\n",
        "    countt = 0\n",
        "    countt_s = 0\n",
        "    sub_count += 1\n",
        "  raw_data, freq = data_load(record, channel_keeps)\n",
        "  if freq != 256:\n",
        "    print('ERROR')\n",
        "    break\n",
        "  # seizure\n",
        "  if part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window']:\n",
        "      # seizure\n",
        "      mid_s = int((part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][1] - part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0])/2) - 10\n",
        "      start_s = part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0]\n",
        "      end_s = part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][1] - 20\n",
        "      for i, channel in enumerate(channel_keeps):\n",
        "        # seizure\n",
        "        x_data[sub_count, 0 + 3*countt_s, :, i] = np.array(raw_data[raw_data['Time'].between(start_s+1,start_s+20)][channel].tolist())\n",
        "        y_data[sub_count, 0 + 3*countt_s] = 1\n",
        "        x_data[sub_count, 1 + 3*countt_s, :, i] = np.array(raw_data[raw_data['Time'].between(mid_s+1,mid_s+20)][channel].tolist())\n",
        "        y_data[sub_count, 1 + 3*countt_s] = 1\n",
        "        x_data[sub_count, 2 + 3*countt_s, :, i] = np.array(raw_data[raw_data['Time'].between(end_s+1,end_s+20)][channel].tolist())\n",
        "        y_data[sub_count, 2 + 3*countt_s] = 1\n",
        "      countt_s += 1\n",
        "  # No seizure\n",
        "  else:\n",
        "      # No seizure\n",
        "      timee = 3600\n",
        "      start = 0\n",
        "      end = timee - 1 - 20\n",
        "      values = np.linspace(start,end,num=9, dtype = int)\n",
        "      #print(values)\n",
        "      for i, channel in enumerate(channel_keeps):\n",
        "        # No seizure\n",
        "        x_data[sub_count, 9, :, i] = np.array(raw_data[raw_data['Time'].between(values[0]+1,values[0]+20)][channel].tolist())\n",
        "        y_data[sub_count, 9] = 0\n",
        "        x_data[sub_count, 10, :, i] = np.array(raw_data[raw_data['Time'].between(values[1]+1,values[1]+20)][channel].tolist())\n",
        "        y_data[sub_count, 10] = 0\n",
        "        x_data[sub_count, 11, :, i] = np.array(raw_data[raw_data['Time'].between(values[2]+1,values[2]+20)][channel].tolist())\n",
        "        y_data[sub_count, 11] = 0\n",
        "        x_data[sub_count, 12, :, i] = np.array(raw_data[raw_data['Time'].between(values[3]+1,values[3]+20)][channel].tolist())\n",
        "        y_data[sub_count, 12] = 0\n",
        "        x_data[sub_count, 13, :, i] = np.array(raw_data[raw_data['Time'].between(values[4]+1,values[4]+20)][channel].tolist())\n",
        "        y_data[sub_count, 13] = 0\n",
        "        x_data[sub_count, 14, :, i] = np.array(raw_data[raw_data['Time'].between(values[5]+1,values[5]+20)][channel].tolist())\n",
        "        y_data[sub_count, 14] = 0\n",
        "        x_data[sub_count, 15, :, i] = np.array(raw_data[raw_data['Time'].between(values[6]+1,values[6]+20)][channel].tolist())\n",
        "        y_data[sub_count, 15] = 0\n",
        "        x_data[sub_count, 16, :, i] = np.array(raw_data[raw_data['Time'].between(values[7]+1,values[7]+20)][channel].tolist())\n",
        "        y_data[sub_count, 16] = 0\n",
        "        x_data[sub_count, 17, :, i] = np.array(raw_data[raw_data['Time'].between(values[8]+1,values[8]+20)][channel].tolist())\n",
        "        y_data[sub_count, 17] = 0        \n",
        "\n",
        "  countt += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsTX2LwMLmH0"
      },
      "source": [
        "x_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBkIXsVRLmH0"
      },
      "source": [
        "y_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtAdWoP7LmH0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBRY6omtLmH0"
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/EMOTION/VQVAE-trans/Trans-checkpoints-py/x_data_ss_i.pkl', 'wb') as filepath:\n",
        "      pickle.dump(x_data, filepath)\n",
        "with open('/content/drive/MyDrive/EMOTION/VQVAE-trans/Trans-checkpoints-py/y_data_ss_i.pkl', 'wb') as filepath:\n",
        "      pickle.dump(y_data, filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II69vQWXLmH1"
      },
      "source": [
        "sub_count "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADsTKa6EerHF"
      },
      "source": [
        "x_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcor4xz_LmH1"
      },
      "source": [
        "## Plot Data\n",
        "\n",
        "Now lets plot the data. We will use the dictionary we made earlier to mark an annotation as to where the seizures are in the record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lSa78RPLmH1"
      },
      "source": [
        "def mne_object(data, freq, events = None):\n",
        "  # create an mne info file with meta data about the EEG\n",
        "  info = mne.create_info(ch_names=list(data.columns), \n",
        "                         sfreq=freq, \n",
        "                         ch_types=['eeg']*data.shape[-1])\n",
        "  \n",
        "  # data needs to be in volts rather than in microvolts\n",
        "  data = data.apply(lambda x: x*1e-6)\n",
        "  # transpose the data\n",
        "  data_T = data.transpose()\n",
        "  \n",
        "  # create raw mne object\n",
        "  raw = mne.io.RawArray(data_T, info)\n",
        "\n",
        "  if events:\n",
        "    start_times = np.array(events[::2])\n",
        "    end_times = np.array(events[1::2])\n",
        "    anno_length = end_times-start_times\n",
        "    event_name = np.array(['Ictal']*len(anno_length))\n",
        "\n",
        "    raw.set_annotations(mne.Annotations(start_times,\n",
        "                                      anno_length,\n",
        "                                      event_name))\n",
        "\n",
        "  return raw\n",
        "\n",
        "mne_data = mne_object(raw_data, freq, part_info_dict[EXAMPLE_ID]['Seizures Window'])\n",
        "\n",
        "\n",
        "mne_data.plot(start = 50, \n",
        "              duration = 30, **plot_kwargs);\n",
        "\n",
        "seiz_start_time = part_info_dict[EXAMPLE_ID]['Seizures Window'][0]\n",
        "mne_data.plot(start = seiz_start_time, \n",
        "              duration = 30, **plot_kwargs);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwFm41xFLmH1"
      },
      "source": [
        "Before we look at random segments again, lets take a second to look at the electrode placement. This is because this is the first *extracranial* dataset (meaning the electrodes are not implanted under the scalp).\n",
        "\n",
        "Scalp EEG is typically gained through placing 21-256 Ag/AgCl electrodes on the scalp, to enable the measurement of the electrical potential between spatially different electrodes. One electrode is dedicated as a *reference* during recording and another as a *ground*. The terms “ground” and “reference” are sometimes used interchangeably, although they refer to separate processes. \n",
        "\n",
        "**Ground Electrode**. \n",
        "A ground electrode is a common reference for the system voltage that aims to cancel out the common-mode interference that occurs from the body naturally picking up electromagnetic interference; particularly around 50/60Hz due to power lines. Unless recording takes place in a Faraday cage, this interference often needs to be filtered out during pre-processing (see next notebook) if not already conducted at time of recording by the amplifier. The ground electrode can be placed anywhere on the body, although the forehead or the ear are the most common<sup>1</sup>. \n",
        "\n",
        "**Reference Electrode**. \n",
        "A reference electrode aims to remove unspecific brain activity by representing the electrical potential between an active electrode of interest and a relatively inactive reference. A reference electrode is also still affected by global voltage changes as it is collected against the signal ground. Referencing can be done either by using a physical reference electrode placed on the earlobe, using any electrode during recording and later re-referencing electrodes to the average output of all electrodes, or by measuring potential between two active electrodes (bipolar recording)<sup>2</sup>. The combination of an active electrode with a reference and a ground creates a *channel*, and the general configuration of these channels are called a *montage*.\n",
        "\n",
        "These channels here are using a bi-polar montage. For ease of plotting, we will change their names to only be the first channel.\n",
        "\n",
        "---\n",
        "\n",
        "1. Light2010\n",
        "\n",
        "2. Varsavsky2011\n",
        "\n",
        "3. Teplan2002"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_qmDNV2LmH1"
      },
      "source": [
        "replace_dict = {}\n",
        "drop_list = []\n",
        "# for the channel names in the data...\n",
        "for channel_name in mne_data.info['ch_names']:\n",
        "    # get the name to change too\n",
        "    name_change = re.findall('\\w+',channel_name)[0].title()\n",
        "    # check if it is already in the change list\n",
        "    if name_change in list(replace_dict.values()):\n",
        "        drop_list.append(channel_name)\n",
        "    else:\n",
        "        # if its not already there get the origional name and what we want to \n",
        "        # change it to\n",
        "        replace_dict[channel_name] = name_change\n",
        "\n",
        "# drop the ones that would be repeats\n",
        "mne_data.drop_channels(drop_list)\n",
        "# rename the channels\n",
        "mne_data.rename_channels(replace_dict)\n",
        "# set the standard montage\n",
        "mne_data.set_montage('standard_1020')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiPm5laKLmH2"
      },
      "source": [
        "Now we have set the names and montage lets plot it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PweeRd7MLmH2"
      },
      "source": [
        "mne_data.plot_sensors(kind='topomap', show_names=True, to_sphere=True);\n",
        "fig = mne_data.plot_sensors(kind='3d', show_names=True, show=False)\n",
        "fig = fig.gca().view_init(azim=70, elev=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3txM2HpKLmH2"
      },
      "source": [
        "EEG has more than just temporal (changes over time) information, it has spatial as well. To demonstate, lets look at how the signal changes over the head before and during a seizure. \n",
        "\n",
        "We will go into different ways of breaking a signal down in more detail in the next notebook, so don't worry if you are not familiar with the welch method I use here. The basic take away is that there is generally more going on!\n",
        "\n",
        "**NOTES**\n",
        "- if you are familiar with the welch method we are just looking at the average power spectral density between 1-40Hz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AkVdJ8_LmH2"
      },
      "source": [
        "from scipy import signal\n",
        "def ave_freq(data):\n",
        "    win = 4 * freq\n",
        "    freqs, psd = signal.welch(data, freq, nperseg=win, scaling='spectrum')\n",
        "    #print(freqs[4:160])\n",
        "    return psd[:,4:160].mean(1)\n",
        "\n",
        "inter_array = mne_data[:, 50*freq:80*freq][0]\n",
        "ictal_array = mne_data[:, (seiz_start_time*freq):(seiz_start_time*freq)+30*freq][0]\n",
        "topo_df = pd.DataFrame([ave_freq(inter_array),ave_freq(ictal_array)], index=['inter', 'ictal'])\n",
        "\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
        "\n",
        "axs = axs.flatten()\n",
        "for i, data_class in enumerate(topo_df.T):\n",
        "    topo, cn = mne.viz.plot_topomap(topo_df.loc[data_class],\n",
        "                                    mne_data.info,\n",
        "                                    show=False,\n",
        "                                    sensors=False,\n",
        "                                    names=mne_data.info['ch_names'], \n",
        "                                    show_names=True,\n",
        "                                    axes = axs[i],\n",
        "                                    vmin = topo_df.values.min(),\n",
        "                                    vmax = topo_df.values.max())\n",
        "    axs[i].set_title(data_class)\n",
        "    \n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACA2z6ntLmH2"
      },
      "source": [
        "Now, as we have done with the other datasets, lets randomly plot different parts of the data to see more examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCC2RtwzLmH2"
      },
      "source": [
        "files_with_seizures = []\n",
        "for file_id in part_info_dict:\n",
        "    # if there is something in the seizure window\n",
        "    if part_info_dict[file_id]['Seizures Window']:\n",
        "        files_with_seizures.append(file_id)\n",
        "\n",
        "sampled_file = random.sample(files_with_seizures, 1)[0]\n",
        "sampled_file_path = sampled_file.split('_')[0]+'/'+sampled_file+'.edf'\n",
        "raw_data, freq = data_load(sampled_file_path, channel_keeps)\n",
        "mne_data = mne_object(raw_data, freq, part_info_dict[sampled_file]['Seizures Window'])\n",
        "\n",
        "print(color.BOLD+color.UNDERLINE+sampled_file+color.END)\n",
        "\n",
        "mne_data.plot(start = 50, \n",
        "              duration = 30, **plot_kwargs);\n",
        "\n",
        "mne_data.plot(start = part_info_dict[sampled_file]['Seizures Window'][0], \n",
        "              duration = 30, **plot_kwargs);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXdRW4qbLmH3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UzlVgOXEAw1"
      },
      "source": [
        "# CHB-MIT Scalp EEG Database Inter Vs Pre\n",
        "\n",
        "The CHB-MIT dataset<sup>1</sup>, consists of records from 23 patients; with one case (chb21) taken from the same patient (chb01) 1.5 years later. The dataset was collected by investigators at the Children’s Hospital Boston and Massachusetts Institute of Technology (MIT). The median length of collection was for 36 hours with small gaps between records each hour due to hardware limitations.\n",
        "\n",
        "The data contains 198 seizures of various types (focal, lateral, and generalised seizures). All signals were recorded at 256 samples per second with most files containing 23 EEG signals positioned using the International 10-20 system (as we will see later). \n",
        "\n",
        "This dataset is one of the most prominent datasets in the literature, as it provides long, continuous recordings for each patient, allowing for both patient specific and patient general models to be developed and tested.\n",
        "\n",
        "\n",
        "| Subject   | Age/Gender | Seizure Events | Total Ictal Time (secs) | Total Inter-ictal Time (secs) |\n",
        "|-----------|------------|----------------|------------------|----------------------|\n",
        "| chb01/chb21 | 11, 13 (F) | 11 | 641  | 263461 |\n",
        "| chb02       | 11 (M)     | 3  | 172  | 126751 |\n",
        "| chb03       | 14 (F)     | 7  | 402  | 136366 |\n",
        "| chb04       | 22 (M)     | 4  | 378  | 561414 |\n",
        "| chb05       | 7 (F)      | 5  | 558  | 139813 |\n",
        "| chb06       | 1.5 (F)    | 10 | 153  | 240075 |\n",
        "| chb07       | 14.5 (F)   | 3  | 325  | 241044 |\n",
        "| chb08       | 3.5 (M)    | 5  | 919  | 71084  |\n",
        "| chb09       | 10 (F)     | 4  | 276  | 244043 |\n",
        "| chb10       | 3 (M)      | 7  | 447  | 179612 |\n",
        "| chb11       | 12 (F)     | 3  | 806  | 124416 |\n",
        "| chb12       | 2 (F)      | 27 | 989  | 73466  |\n",
        "| chb13       | 3 (F)      | 12 | 535  | 118232 |\n",
        "| chb14       | 9 (F)      | 8  | 169  | 93405  |\n",
        "| chb15       | 16 (M)     | 20 | 1992 | 142004 |\n",
        "| chb16       | 7 (F)      | 10 | 84   | 68297  |\n",
        "| chb17       | 12 (F)     | 3  | 293  | 75310  |\n",
        "| chb18       | 18 (F)     | 6  | 317  | 127932 |\n",
        "| chb19       | 19 (F)     | 3  | 236  | 107480 |\n",
        "| chb20       | 6 (F)      | 8  | 294  | 99043  |\n",
        "| chb22       | 9 (F)      | 3  | 204  | 111376 |\n",
        "| chb23       | 6 (F)      | 7  | 424  | 95177  |\n",
        "| chb24       | NR (NR)    | 16 | 511  | 76134  |\n",
        "| **Total**   | -          | **185**| **11125**| **3515935**|\n",
        "\n",
        "**NOTE**\n",
        "- You may have noticed that in the table above it actually only totals to 185 seizures. Thats because the method I use to load the data into Python does not work on a select few files. This reduces the number of seizure events from 40 to 27 in patient 12 by not including files 27, 28, and 29.\n",
        "\n",
        "---\n",
        "1. Shoeb2009"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxtxs4C4EAw5"
      },
      "source": [
        "## Data Information\n",
        "The dataset is stored on Physionet which has some helpful tools to access the data. We are going to use one such package (wfdb) to get a list of the records in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZgS026AEAw5"
      },
      "source": [
        "import wfdb \n",
        "\n",
        "dbs = wfdb.get_dbs()\n",
        "\n",
        "records_list = wfdb.io.get_record_list('chbmit', records='all')\n",
        "records_list[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI9S2qegEAw6"
      },
      "source": [
        "records_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jirhOfYtEAw6"
      },
      "source": [
        "Using the above, lets get a list of the unique directory names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZQKrlxqEAw6"
      },
      "source": [
        "part_codes = sorted(list(set([record.split('/')[0] for record in records_list])))\n",
        "part_codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoZR1RX8EAw8"
      },
      "source": [
        "Each patient has an information file associate with it. Lets load one in and have a look at how it looks before we parse it into something more useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB1-zi1FEAw8"
      },
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "def get_content(part_code):\n",
        "  url = \"https://physionet.org/physiobank/database/chbmit/\"+part_code+'/'+part_code+'-summary.txt'\n",
        "  filename = \"./chbmit.txt\"\n",
        "\n",
        "  urlretrieve(url,filename)\n",
        "\n",
        "  # read the file into a list\n",
        "  with open(filename, encoding='UTF-8') as f:\n",
        "      # read all the document into a list of strings (each line a new string)\n",
        "      content = f.readlines()\n",
        "      os.remove(filename)\n",
        "\n",
        "  return content\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9yGZULKEAw8"
      },
      "source": [
        "get_content(part_codes[23])#[6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-OmfsaOEAw9"
      },
      "source": [
        "Taking the above, the below function below just parses this file up into a Python dictionary format we can use later. See the output for an example of what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfsaG052EAw9"
      },
      "source": [
        "import re\n",
        "part_info_dict = {}\n",
        "\n",
        "def info_dict(content):\n",
        "  \n",
        "  line_nos=len(content)\n",
        "  line_no=1\n",
        "  count = 0\n",
        "\n",
        "  channels = []\n",
        "  file_name = []\n",
        "  file_info_dict={}\n",
        "\n",
        "  for line in content:\n",
        "\n",
        "    # if there is Channel in the line...\n",
        "    if re.findall('Channel \\d+', line):\n",
        "      # split the line into channel number and channel reference\n",
        "      channel = line.split(': ')\n",
        "      # get the channel reference and remove any new lines\n",
        "      channel = channel[-1].replace(\"\\n\", \"\")\n",
        "      # put into the channel list\n",
        "      channels.append(channel)\n",
        "\n",
        "    # if the line is the file name\n",
        "    elif re.findall('File Name', line):\n",
        "      # if there is already a file_name\n",
        "      if file_name:\n",
        "        # flush the current file info to it\n",
        "        if file_info_dict['Seizures Window'] or not(count):\n",
        "          count = 1\n",
        "          part_info_dict[file_name] = file_info_dict\n",
        "\n",
        "      # get the file name\n",
        "      file_name = re.findall('\\w+\\d+_\\d+|\\w+\\d+\\w+_\\d+', line)[0]\n",
        "\n",
        "      file_info_dict = {}\n",
        "      # put the channel list in the file info dict and remove duplicates\n",
        "      file_info_dict['Channels'] = list(set(channels))\n",
        "      # reset the rest of the options\n",
        "      file_info_dict['Start Time'] = ''\n",
        "      file_info_dict['End Time'] = ''\n",
        "      file_info_dict['Seizures Window'] = []\n",
        "\n",
        "    # if the line is about the file start time\n",
        "    elif re.findall('File Start Time', line):\n",
        "      # get the start time\n",
        "      file_info_dict['Start Time'] = re.findall('\\d+:\\d+:\\d+', line)[0]\n",
        "\n",
        "    # if the line is about the file end time\n",
        "    elif re.findall('File End Time', line):\n",
        "      # get the start time\n",
        "      file_info_dict['End Time'] = re.findall('\\d+:\\d+:\\d+', line)[0]\n",
        "\n",
        "    elif re.findall('Seizure Start Time|Seizure End Time|Seizure \\d+ Start Time|Seizure \\d+ End Time', line):\n",
        "      file_info_dict['Seizures Window'].append(int(re.findall('\\d+', line)[-1]))\n",
        "\n",
        "    # if last line in the list...\n",
        "    if line_no == line_nos:\n",
        "      # flush the file info to it\n",
        "      if file_info_dict['Seizures Window'] or not(count):\n",
        "          count = 1\n",
        "          part_info_dict[file_name] = file_info_dict\n",
        "\n",
        "    line_no+=1\n",
        "    \n",
        "        \n",
        "for part_code in part_codes:\n",
        "  content = get_content(part_code)\n",
        "  info_dict(content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiRrz_cLEAw9"
      },
      "source": [
        "print(color.BOLD+color.UNDERLINE+'part_info_dict'+color.END)\n",
        "display(part_info_dict['chb24_13'])\n",
        "print(color.UNDERLINE+'\\nPart Keys'+color.END)\n",
        "print(part_info_dict[list(part_info_dict.keys())[0]].keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uno4f1ErEAw9"
      },
      "source": [
        "# part_info_dict_new = dict()\n",
        "\n",
        "# for i in range(len(records_list)):\n",
        "#   filee1 = records_list[i].split('/')[1].split('.')[0]\n",
        "#   filee2 = records_list[i-1].split('/')[1].split('.')[0]\n",
        "#   #print(filee)\n",
        "#   try:\n",
        "#     num = int(records_list[i].split('/')[1].split('.')[0][-2:])\n",
        "#     num2 = int(records_list[i-1].split('/')[1].split('.')[0][-2:])\n",
        "#     check1 = part_info_dict[filee1]\n",
        "#     check2 = part_info_dict[filee2]\n",
        "#   except:\n",
        "#     continue\n",
        "#   if part_info_dict[filee1]['Seizures Window'] and num > 2:\n",
        "#     part_info_dict_new[filee2] = part_info_dict[filee2]\n",
        "#     part_info_dict_new[filee1] = part_info_dict[filee1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAMWcL-dEAw-"
      },
      "source": [
        "part_info_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiFk1XkMEAw-"
      },
      "source": [
        "As can be seen below there is a common set of channels found in ALL patients, but there are also some channels only found in individual patients. This is because sometimes channels were swapped during recording for others. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TeiWnNlEAw-"
      },
      "source": [
        "import pandas as pd     # dataframes\n",
        "import re\n",
        "\n",
        "all_channels = []\n",
        "\n",
        "for key in part_info_dict.keys():\n",
        "    all_channels.extend(part_info_dict[key]['Channels'])\n",
        "    \n",
        "# turn the list into a pandas series\n",
        "all_channels = pd.Series(all_channels)\n",
        "\n",
        "# count how many times the channels appear in each participant\n",
        "channel_counts = all_channels.value_counts()\n",
        "channel_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XR2CM3YEAw_"
      },
      "source": [
        "To deal with the fact some channels are only found in individual patients, I tend to keep channels found in all the patients. This makes generalising models across patients easier, however if you are only training models to identify a particular patients seizures you wouldnt need to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4uz7x6KEAw_"
      },
      "source": [
        "threshold = len(part_info_dict.keys())\n",
        "channel_keeps = list(channel_counts[channel_counts >= threshold].index)\n",
        "channel_keeps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48ezd6xTEAxA"
      },
      "source": [
        "## Load Data\n",
        "Lets now load in some example data. First lets choose a file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUv2YJJ7EAxA"
      },
      "source": [
        "records_list_new = []\n",
        "\n",
        "for record in records_list:\n",
        "  try :\n",
        "    part_info_dict[record.split('/')[1].split('.')[0]]\n",
        "  except : \n",
        "    #print('Nope : ',record)\n",
        "    continue\n",
        "  if not(part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window']):\n",
        "    records_list_new.append(record)\n",
        "  elif part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][1] - part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0] >= 30*2:\n",
        "    records_list_new.append(record)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI9d0VX_EAxA"
      },
      "source": [
        "len(records_list_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAr0Tw1hEAxA"
      },
      "source": [
        "EXAMPLE_FILE = records_list_new[0]\n",
        "EXAMPLE_ID = EXAMPLE_FILE.split('/')[1].split('.')[0]\n",
        "EXAMPLE_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxHXl5iOEAxA"
      },
      "source": [
        "sub_freq = dict()\n",
        "\n",
        "for record in records_list_new:\n",
        "  if record.split('/')[1].split('.')[0][:-3] in sub_freq:\n",
        "    sub_freq[record.split('/')[1].split('.')[0][:-3]] += 1\n",
        "  else:\n",
        "    sub_freq[record.split('/')[1].split('.')[0][:-3]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2CjTNYgEAxB"
      },
      "source": [
        "sub_freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA0Ix9uLEAxB"
      },
      "source": [
        "records_list_new_new = []\n",
        "count = 0\n",
        "last = ''\n",
        "\n",
        "for record in records_list_new:\n",
        "  sub_f = sub_freq[record.split('/')[1].split('.')[0][:-3]]\n",
        "  sub = record.split('/')[1].split('.')[0][:-3]\n",
        "  if sub_f >= 4 and count < 4: \n",
        "    records_list_new_new.append(record)\n",
        "    count += 1\n",
        "    last = sub\n",
        "  elif sub_f >= 4 and sub != last:\n",
        "    count = 0\n",
        "    records_list_new_new.append(record)\n",
        "    count += 1\n",
        "    last = sub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb0lHzUyEAxB"
      },
      "source": [
        "sub_freq2 = dict()\n",
        "\n",
        "for record in records_list_new_new:\n",
        "  if record.split('/')[1].split('.')[0][:-3] in sub_freq2:\n",
        "    sub_freq2[record.split('/')[1].split('.')[0][:-3]] += 1\n",
        "  else:\n",
        "    sub_freq2[record.split('/')[1].split('.')[0][:-3]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIFHXh2WEAxB"
      },
      "source": [
        "sub_freq2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zky6nBZSEAxB"
      },
      "source": [
        "max = 0\n",
        "min = 1000000\n",
        "for record in records_list_new_new:\n",
        "  if not(part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window']):\n",
        "    continue\n",
        "  temp = part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0] #- part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0]\n",
        "  if temp > max:\n",
        "    max = temp\n",
        "  if temp < min:\n",
        "    min = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVq2OBPCEAxC"
      },
      "source": [
        "max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU0ZSAh6EAxC"
      },
      "source": [
        "min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct5GVElCEAxC"
      },
      "source": [
        "Now using the function below I can download the data and then load it into a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx3TsPimEAxC"
      },
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyedflib\n",
        "\n",
        "def data_load(file, selected_channels=[]):\n",
        "\n",
        "  try: \n",
        "    url = \"https://physionet.org/physiobank/database/chbmit/\"+file\n",
        "    filename = \"./chbmit.edf\"\n",
        "\n",
        "    urlretrieve(url,filename)\n",
        "    # use the reader to get an EdfReader file\n",
        "    f = pyedflib.EdfReader(filename)\n",
        "    os.remove(filename)\n",
        "    \n",
        "    # get a list of the EEG channels\n",
        "    if len(selected_channels) == 0:\n",
        "      selected_channels = f.getSignalLabels()\n",
        "\n",
        "    # get the names of the signals\n",
        "    channel_names = f.getSignalLabels()\n",
        "    # get the sampling frequencies of each signal\n",
        "    channel_freq = f.getSampleFrequencies()\n",
        "\n",
        "    # make an empty file of 0's\n",
        "    sigbufs = np.zeros((f.getNSamples()[0],len(selected_channels)))\n",
        "    # for each of the channels in the selected channels\n",
        "    for i, channel in enumerate(selected_channels):\n",
        "      # add the channel data into the array\n",
        "      sigbufs[:, i] = f.readSignal(channel_names.index(channel))\n",
        "    \n",
        "    # turn to a pandas df and save a little space\n",
        "    df = pd.DataFrame(sigbufs, columns = selected_channels).astype('float32')\n",
        "    \n",
        "    # get equally increasing numbers upto the length of the data depending\n",
        "    # on the length of the data divided by the sampling frequency\n",
        "    index_increase = np.linspace(0,\n",
        "                                 len(df)/channel_freq[0],\n",
        "                                 len(df), endpoint=False)\n",
        "\n",
        "    # round these to the lowest nearest decimal to get the seconds\n",
        "    seconds = np.floor(index_increase).astype('uint16')\n",
        "\n",
        "    # make a column the timestamp\n",
        "    df['Time'] = seconds\n",
        "\n",
        "    # make the time stamp the index\n",
        "    #df = df.set_index('Time')\n",
        "\n",
        "    # name the columns as channel\n",
        "    #df.columns.name = 'Channel'\n",
        "\n",
        "    return df, channel_freq[0]\n",
        "\n",
        "  except:\n",
        "    OSError\n",
        "    return pd.DataFrame(), None\n",
        "\n",
        "\n",
        "raw_data, freq = data_load(EXAMPLE_FILE, channel_keeps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfB79eDdEAxC"
      },
      "source": [
        "channel_keeps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy5OVYvnEAxD"
      },
      "source": [
        "display(raw_data)#[channel_keeps[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu_Qrtc8EAxD"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x_data = np.zeros((len(sub_freq2), 18, 256*20, len(channel_keeps)))\n",
        "y_data = np.zeros((len(sub_freq2), 18))\n",
        "\n",
        "countt = 0 \n",
        "countt_s = 0\n",
        "sub_count = 0\n",
        "\n",
        "for record in tqdm(records_list_new_new):\n",
        "  if countt >= 4:\n",
        "    countt = 0\n",
        "    countt_s = 0\n",
        "    sub_count += 1\n",
        "  raw_data, freq = data_load(record, channel_keeps)\n",
        "  if freq != 256:\n",
        "    print('ERROR')\n",
        "    break\n",
        "  # seizure\n",
        "  if part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window']:\n",
        "      # Pre Seizure\n",
        "      start_p = 0\n",
        "      mid_p = int(part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0]/2 ) - 10\n",
        "      end_p = part_info_dict[record.split('/')[1].split('.')[0]]['Seizures Window'][0] - 1 - 20\n",
        "      for i, channel in enumerate(channel_keeps):\n",
        "        # Pre seizure\n",
        "        x_data[sub_count, 0 + 3*countt_s, :, i] = np.array(raw_data[raw_data['Time'].between(start_p+1,start_p+20)][channel].tolist())\n",
        "        y_data[sub_count, 0 + 3*countt_s] = 1\n",
        "        x_data[sub_count, 1 + 3*countt_s, :, i] = np.array(raw_data[raw_data['Time'].between(mid_p+1,mid_p+20)][channel].tolist())\n",
        "        y_data[sub_count, 1 + 3*countt_s] = 1\n",
        "        x_data[sub_count, 2 + 3*countt_s, :, i] = np.array(raw_data[raw_data['Time'].between(end_p+1,end_p+20)][channel].tolist())\n",
        "        y_data[sub_count, 2 + 3*countt_s] = 1\n",
        "      countt_s += 1\n",
        "  # No seizure\n",
        "  else:\n",
        "      # No seizure\n",
        "      timee = 3600\n",
        "      start = 0\n",
        "      end = timee - 1 - 20\n",
        "      values = np.linspace(start,end,num=9, dtype = int)\n",
        "      #print(values)\n",
        "      for i, channel in enumerate(channel_keeps):\n",
        "        # No seizure\n",
        "        x_data[sub_count, 9, :, i] = np.array(raw_data[raw_data['Time'].between(values[0]+1,values[0]+20)][channel].tolist())\n",
        "        y_data[sub_count, 9] = 0\n",
        "        x_data[sub_count, 10, :, i] = np.array(raw_data[raw_data['Time'].between(values[1]+1,values[1]+20)][channel].tolist())\n",
        "        y_data[sub_count, 10] = 0\n",
        "        x_data[sub_count, 11, :, i] = np.array(raw_data[raw_data['Time'].between(values[2]+1,values[2]+20)][channel].tolist())\n",
        "        y_data[sub_count, 11] = 0\n",
        "        x_data[sub_count, 12, :, i] = np.array(raw_data[raw_data['Time'].between(values[3]+1,values[3]+20)][channel].tolist())\n",
        "        y_data[sub_count, 12] = 0\n",
        "        x_data[sub_count, 13, :, i] = np.array(raw_data[raw_data['Time'].between(values[4]+1,values[4]+20)][channel].tolist())\n",
        "        y_data[sub_count, 13] = 0\n",
        "        x_data[sub_count, 14, :, i] = np.array(raw_data[raw_data['Time'].between(values[5]+1,values[5]+20)][channel].tolist())\n",
        "        y_data[sub_count, 14] = 0\n",
        "        x_data[sub_count, 15, :, i] = np.array(raw_data[raw_data['Time'].between(values[6]+1,values[6]+20)][channel].tolist())\n",
        "        y_data[sub_count, 15] = 0\n",
        "        x_data[sub_count, 16, :, i] = np.array(raw_data[raw_data['Time'].between(values[7]+1,values[7]+20)][channel].tolist())\n",
        "        y_data[sub_count, 16] = 0\n",
        "        x_data[sub_count, 17, :, i] = np.array(raw_data[raw_data['Time'].between(values[8]+1,values[8]+20)][channel].tolist())\n",
        "        y_data[sub_count, 17] = 0        \n",
        "\n",
        "  countt += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oko8z6qREAxD"
      },
      "source": [
        "x_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOJhqdaaEAxD"
      },
      "source": [
        "y_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOWUnCnrEAxE"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glTESp3aEAxE"
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/EMOTION/VQVAE-trans/Trans-checkpoints-py/x_data_ss_ip.pkl', 'wb') as filepath:\n",
        "      pickle.dump(x_data, filepath)\n",
        "with open('/content/drive/MyDrive/EMOTION/VQVAE-trans/Trans-checkpoints-py/y_data_ss_ip.pkl', 'wb') as filepath:\n",
        "      pickle.dump(y_data, filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BI2XOC_EAxE"
      },
      "source": [
        "sub_count "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bbmQ5T-EAxE"
      },
      "source": [
        "x_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmnNt_gAEAxE"
      },
      "source": [
        "## Plot Data\n",
        "\n",
        "Now lets plot the data. We will use the dictionary we made earlier to mark an annotation as to where the seizures are in the record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4DeX2-yEAxF"
      },
      "source": [
        "def mne_object(data, freq, events = None):\n",
        "  # create an mne info file with meta data about the EEG\n",
        "  info = mne.create_info(ch_names=list(data.columns), \n",
        "                         sfreq=freq, \n",
        "                         ch_types=['eeg']*data.shape[-1])\n",
        "  \n",
        "  # data needs to be in volts rather than in microvolts\n",
        "  data = data.apply(lambda x: x*1e-6)\n",
        "  # transpose the data\n",
        "  data_T = data.transpose()\n",
        "  \n",
        "  # create raw mne object\n",
        "  raw = mne.io.RawArray(data_T, info)\n",
        "\n",
        "  if events:\n",
        "    start_times = np.array(events[::2])\n",
        "    end_times = np.array(events[1::2])\n",
        "    anno_length = end_times-start_times\n",
        "    event_name = np.array(['Ictal']*len(anno_length))\n",
        "\n",
        "    raw.set_annotations(mne.Annotations(start_times,\n",
        "                                      anno_length,\n",
        "                                      event_name))\n",
        "\n",
        "  return raw\n",
        "\n",
        "mne_data = mne_object(raw_data, freq, part_info_dict[EXAMPLE_ID]['Seizures Window'])\n",
        "\n",
        "\n",
        "mne_data.plot(start = 50, \n",
        "              duration = 30, **plot_kwargs);\n",
        "\n",
        "seiz_start_time = part_info_dict[EXAMPLE_ID]['Seizures Window'][0]\n",
        "mne_data.plot(start = seiz_start_time, \n",
        "              duration = 30, **plot_kwargs);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEppaPfVEAxF"
      },
      "source": [
        "Before we look at random segments again, lets take a second to look at the electrode placement. This is because this is the first *extracranial* dataset (meaning the electrodes are not implanted under the scalp).\n",
        "\n",
        "Scalp EEG is typically gained through placing 21-256 Ag/AgCl electrodes on the scalp, to enable the measurement of the electrical potential between spatially different electrodes. One electrode is dedicated as a *reference* during recording and another as a *ground*. The terms “ground” and “reference” are sometimes used interchangeably, although they refer to separate processes. \n",
        "\n",
        "**Ground Electrode**. \n",
        "A ground electrode is a common reference for the system voltage that aims to cancel out the common-mode interference that occurs from the body naturally picking up electromagnetic interference; particularly around 50/60Hz due to power lines. Unless recording takes place in a Faraday cage, this interference often needs to be filtered out during pre-processing (see next notebook) if not already conducted at time of recording by the amplifier. The ground electrode can be placed anywhere on the body, although the forehead or the ear are the most common<sup>1</sup>. \n",
        "\n",
        "**Reference Electrode**. \n",
        "A reference electrode aims to remove unspecific brain activity by representing the electrical potential between an active electrode of interest and a relatively inactive reference. A reference electrode is also still affected by global voltage changes as it is collected against the signal ground. Referencing can be done either by using a physical reference electrode placed on the earlobe, using any electrode during recording and later re-referencing electrodes to the average output of all electrodes, or by measuring potential between two active electrodes (bipolar recording)<sup>2</sup>. The combination of an active electrode with a reference and a ground creates a *channel*, and the general configuration of these channels are called a *montage*.\n",
        "\n",
        "These channels here are using a bi-polar montage. For ease of plotting, we will change their names to only be the first channel.\n",
        "\n",
        "---\n",
        "\n",
        "1. Light2010\n",
        "\n",
        "2. Varsavsky2011\n",
        "\n",
        "3. Teplan2002"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vaYKa8eEAxF"
      },
      "source": [
        "replace_dict = {}\n",
        "drop_list = []\n",
        "# for the channel names in the data...\n",
        "for channel_name in mne_data.info['ch_names']:\n",
        "    # get the name to change too\n",
        "    name_change = re.findall('\\w+',channel_name)[0].title()\n",
        "    # check if it is already in the change list\n",
        "    if name_change in list(replace_dict.values()):\n",
        "        drop_list.append(channel_name)\n",
        "    else:\n",
        "        # if its not already there get the origional name and what we want to \n",
        "        # change it to\n",
        "        replace_dict[channel_name] = name_change\n",
        "\n",
        "# drop the ones that would be repeats\n",
        "mne_data.drop_channels(drop_list)\n",
        "# rename the channels\n",
        "mne_data.rename_channels(replace_dict)\n",
        "# set the standard montage\n",
        "mne_data.set_montage('standard_1020')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUmtEmQIEAxF"
      },
      "source": [
        "Now we have set the names and montage lets plot it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHstNuGHEAxF"
      },
      "source": [
        "mne_data.plot_sensors(kind='topomap', show_names=True, to_sphere=True);\n",
        "fig = mne_data.plot_sensors(kind='3d', show_names=True, show=False)\n",
        "fig = fig.gca().view_init(azim=70, elev=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6B7UaYmEAxG"
      },
      "source": [
        "EEG has more than just temporal (changes over time) information, it has spatial as well. To demonstate, lets look at how the signal changes over the head before and during a seizure. \n",
        "\n",
        "We will go into different ways of breaking a signal down in more detail in the next notebook, so don't worry if you are not familiar with the welch method I use here. The basic take away is that there is generally more going on!\n",
        "\n",
        "**NOTES**\n",
        "- if you are familiar with the welch method we are just looking at the average power spectral density between 1-40Hz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJV5bwlmlzh9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huFSL-oJl68a"
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/EMOTION/encoder/DSEQAE_ecoded_dataset_mse88_nzz7680_attn444__bino_all2.pkl', 'rb') as filepath:\n",
        "          x_data = pickle.load(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I0MU8-4l7Am"
      },
      "source": [
        "# import mne"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY4BSrsDmsyD"
      },
      "source": [
        "x_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9UjgnL1l7EF"
      },
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import h5py\n",
        "import scipy.io as sio\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "# from cuml.manifold import TSNE\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9J_RmbNtjDH"
      },
      "source": [
        "def ZscoreNormalization(x):\n",
        "    \"\"\"Z-score normaliaztion\"\"\"\n",
        "    x = (x - np.mean(x)) / np.std(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2be2duZfth4y"
      },
      "source": [
        "xxx = ZscoreNormalization(x_data[10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx2sooNYrvYe"
      },
      "source": [
        "plt.plot(xxx[100:200])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vnLjXwmsTEM"
      },
      "source": [
        "plt.plot(xxx[1200])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oCWGKIsr6u6"
      },
      "source": [
        "np.mean(xxx[:1000], axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_wQQ29tsGoP"
      },
      "source": [
        "np.mean(xxx[1000:2000], axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LzlLkHosG-d"
      },
      "source": [
        "np.mean(x_data[0,:1000], axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2I8fBO0EAxG"
      },
      "source": [
        "from scipy import signal\n",
        "def ave_freq(data):\n",
        "    win = 4 * freq\n",
        "    freqs, psd = signal.welch(data, freq, nperseg=win, scaling='spectrum')\n",
        "    #print(freqs[4:160])\n",
        "    return psd[:,4:160].mean(1)\n",
        "\n",
        "inter_array = mne_data[:, 50*freq:80*freq][0]\n",
        "ictal_array = mne_data[:, (seiz_start_time*freq):(seiz_start_time*freq)+30*freq][0]\n",
        "topo_df = pd.DataFrame([ave_freq(inter_array),ave_freq(ictal_array)], index=['inter', 'ictal'])\n",
        "\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
        "\n",
        "axs = axs.flatten()\n",
        "for i, data_class in enumerate(topo_df.T):\n",
        "    topo, cn = mne.viz.plot_topomap(topo_df.loc[data_class],\n",
        "                                    mne_data.info,\n",
        "                                    show=False,\n",
        "                                    sensors=False,\n",
        "                                    names=mne_data.info['ch_names'], \n",
        "                                    show_names=True,\n",
        "                                    axes = axs[i],\n",
        "                                    vmin = topo_df.values.min(),\n",
        "                                    vmax = topo_df.values.max())\n",
        "    axs[i].set_title(data_class)\n",
        "    \n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YILvCiRqEAxG"
      },
      "source": [
        "Now, as we have done with the other datasets, lets randomly plot different parts of the data to see more examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h47j1uuSEAxG"
      },
      "source": [
        "files_with_seizures = []\n",
        "for file_id in part_info_dict:\n",
        "    # if there is something in the seizure window\n",
        "    if part_info_dict[file_id]['Seizures Window']:\n",
        "        files_with_seizures.append(file_id)\n",
        "\n",
        "sampled_file = random.sample(files_with_seizures, 1)[0]\n",
        "sampled_file_path = sampled_file.split('_')[0]+'/'+sampled_file+'.edf'\n",
        "raw_data, freq = data_load(sampled_file_path, channel_keeps)\n",
        "mne_data = mne_object(raw_data, freq, part_info_dict[sampled_file]['Seizures Window'])\n",
        "\n",
        "print(color.BOLD+color.UNDERLINE+sampled_file+color.END)\n",
        "\n",
        "mne_data.plot(start = 50, \n",
        "              duration = 30, **plot_kwargs);\n",
        "\n",
        "mne_data.plot(start = part_info_dict[sampled_file]['Seizures Window'][0], \n",
        "              duration = 30, **plot_kwargs);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvpAcG6QEAxG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}